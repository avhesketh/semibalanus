---
title: "Semibalanus mortality analysis"
author: "Amelia Hesketh"
date: "06/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objectives

Following the heat dome of 2021, my goal was to document resultant impacts on the mortality of the bed-forming thatched barnacle <i>Semibalanus cariosus</i>, and the determine the dominant factors underlying any mortality patterns observed.

## Data involved

The response, barnacle mortality, is a percentage value obtained by counting the number of live and number of dead barnacles present in 12.7x12.7 cm quadrats along haphazardly placed transects at each site (10 quadrats/transect, 1-3 transects per site). Algal cover and the number of anemones (<i>Anthopleura elegantissima</i>) in each quadrat were documented in most cases to serve as covariates.

Temperature data was obtained from Climate Canada. While numerous temperature metrics may be suitable, we will attempt to use the a) mean daily maximum temperature during the heat dome period in British Columbia (June 25-29), and b) mean daily maximum temperature during the start of summer to the time of each mortality survey.

In addition, we will consider the dominant shore aspect and timing of the low tide (to the nearest hour).

We hypothesize that:

1. Mortality will increase with higher air temperature (both for the heat wave and overall during summer).
2) Mortality will increase with proximity of shore aspect to the south
3) Mortality will increase as the tide falls later in the day (to coincide with high air temps). Air temp * time of tide will be significant since high max air temp later in the day will have no bearing on survival if barnacles immersed.
4) Mortality will be reduced by algal cover since this buffers extreme temp.

## Modeling approach

We will attempt to model mortality using a generalized linear modeling approach with a beta family (given that proportion data are being used). We may need to transform the data in order to pull zero mortality data above zero, since GLMMTMB can only handle data on the interval (0,1), not [0,1].


```{r}
# make figure to show magnitude of heat wave
# missing data: impute tofino data by day & time using other sites (Esquimalt & Bella Bella)

tbl <- list.files("../raw_data/hourly_temps_figure/impute/", full.names = T) %>% map_df(~read_csv(., col_select = c(3, 5:8, 10))) %>% rename(site = 1, date_time = 2, temp = 6) %>% mutate(date_time = ymd_hms(date_time)) %>% mutate(time = hour(date_time), Day = as.numeric(Day), Month = as.numeric(Month)) %>% filter(date_time <= ymd_hms("2021-07-01 23:00:00") & date_time >= ymd_hms("2021-06-23 00:00:00"))

X <- na_ma(tbl,k=10, weighting = "linear")
plot(temp ~ date_time, data = X %>% filter(site == "TOFINO A"))
hourly.temp.impute <- mice(tbl %>% select(temp, Month, Day, time, site), m = 5, maxit = 500, method = "pmm", seed = 500)

hourly.temp.tofino <- complete(hourly.temp.impute %>% filter(site == "TOFINO A")) %>% mutate(date_time = ymd_h(paste(paste(paste("2021",Month,sep = "-"), Day, sep = "-"), time, sep = " ")))

# plot against seasonal norms

bamfield.panel <- ggplot(data = tbl %>% filter(site == "TOFINO A"), aes(x = date_time)) + geom_line(aes(y = temp), col = "olivedrab4", lwd = 1) + annotate(geom = "rect", xmin = ymd_hms("2021-06-23 00:00:00"), xmax = ymd_hms("2021-06-30 23:00:00"), ymin = 8.9, ymax = 16.8, alpha = 0.3) + geom_line(aes(y = 12.9), lty = "dotted") + labs(x = "Date", y = "Temperature (ºC)") + coord_cartesian(xlim = c(ymd_hms("2021-06-23 00:00:00"), ymd_hms("2021-06-30 23:00:00")), expand = F, ylim = c(5,40)) + theme_classic() + theme(axis.title = element_text(size = 14), axis.text = element_text(size = 12))
bamfield.panel # still odd. imputation is making temp high at 10 PM, which isn't accurate
# just go without.


hourly.temp.vic <- read_csv("../raw_data/hourly_temps_figure/hourly_temp_vicairport.csv", col_select = c(5:8, 10, 14)) %>% filter(Day <= 30 & Day >=23) %>% rename(date_time = 1, temp = 5, humidity = 6) %>% mutate(date_time = ymd_hms(date_time))

yyj.panel <- ggplot(data = hourly.temp.vic, aes(x = date_time)) + geom_line(aes(y = temp), col = "mediumorchid4", lwd = 1) + annotate(geom = "rect", xmin = ymd_hms("2021-06-23 00:00:00"), xmax = ymd_hms("2021-06-30 23:00:00"), ymin = 9.8, ymax = 19.9, alpha = 0.3) + geom_line(aes(y = 14.9), lty = "dotted") + labs(x = "Date", y = "Temperature (ºC)") + coord_cartesian(xlim = c(ymd_hms("2021-06-23 00:00:00"), ymd_hms("2021-06-30 23:00:00")), expand = F, ylim = c(5,40)) + theme_classic() + theme(axis.title = element_text(size = 14), axis.text = element_text(size = 12))
yyj.panel

hourly.temp.bellabella <-read_csv("../raw_data/hourly_temps_figure/temp_bellabella_june.csv", col_select = c(5:8, 10, 14)) %>% filter(Day <= 30 & Day >=23) %>% rename(date_time = 1, temp = 5, humidity = 6) %>% mutate(date_time = ymd_hms(date_time))

bb.panel <- ggplot(data = hourly.temp.bellabella, aes(x = date_time)) + geom_line(aes(y = temp), col = "olivedrab4", lwd = 1) + annotate(geom = "rect", xmin = ymd_hms("2021-06-23 00:00:00"), xmax = ymd_hms("2021-06-30 23:00:00"), ymin = 9.9, ymax = 19.0, alpha = 0.3) + geom_line(aes(y = 13.5), lty = "dotted") + labs(x = "Date", y = "Temperature (ºC)") + coord_cartesian(xlim = c(ymd_hms("2021-06-23 00:00:00"), ymd_hms("2021-06-30 23:00:00")), expand = F, ylim = c(5,40)) + theme_classic() + theme(axis.title = element_text(size = 14), axis.text = element_text(size = 12))
bb.panel

S1Fig1 <- bb.panel / yyj.panel + plot_annotation(tag_levels = "A") & theme(plot.tag = element_text(face = "bold"))

ggsave(S1Fig1, filename = "../outputs/S1Fig1.png", dpi = 1200, width = 7, height = 5, units = "in" )
```



## Assembling temperature data

```{r, results='hide', message = F}
library(tidyverse)
library(lubridate)

# first, assemble all relevant air temperature data

temp.files <- list.files("../raw_data/air_temp/")

# join together all the files

for (file in 1: length(temp.files)){
  file.name = paste("../raw_data/air_temp/", temp.files[file], sep = "")
  file.name.len = nchar(file.name)
  site.name = substr(file.name, (file.name.len-5), (file.name.len-4))
  temp.df <- read_csv(file.name, col_select = c(5:8, 10, 14)) %>% 
    filter(`Date/Time` >= "2021-06-01" & `Date/Time` < "2021-09-01") %>% 
    mutate(site_code = site.name)
  if (file == 1){
    temp.df.all <- temp.df
  }
  if (file > 1){
    temp.df.all <- rbind(temp.df.all, temp.df)
  }
}

# now to rename the columns for ease of coding later
temp.df.rename <- temp.df.all %>% rename("date" = 1, "year" = 2,"month" = 3, "day" = 4, "max_temp_C" = 5, "mean_temp_C" = 6)

# need to next associate each site with a sampling date, and filter out any temp data that was recorded after

survey.info <- read_csv("../raw_data/SBC_siteinformation.csv") %>% 
  select(site_code, latitude_degrees, longitude_degrees, mortality, mortality_survey, orientation_degrees, solar_azimuth)  %>% na.omit() %>% mutate(degrees_from_azimuth = abs(orientation_degrees-solar_azimuth))

survey.dates <- survey.info %>% select(site_code, mortality_survey)

# now join to temperature data, leaving out sites we don't yet have mortality data for

required.temp.data <- temp.df.rename %>% right_join(survey.dates) %>% 
  filter(date < mortality_survey) %>% select(-mortality_survey)

# now summarize mean daily temperature values that we care about across whole period

temp.summary <- required.temp.data %>% 
  group_by(site_code) %>% summarize(mean_daily_temp = mean(mean_temp_C, na.rm=T), mean_daily_max_temp = mean(max_temp_C, na.rm=T)) %>% mutate(site_code = if_else(site_code == "BS", "WBS", site_code))

# now just for the heat wave period

temp.hw.only <- temp.df.rename %>% filter(date <= "2021-06-29" & date >= "2021-06-25")

# join to site information data frame

explanatory.variables <- survey.info %>% left_join(temp.hw.summary) %>% 
   select(-mortality, -mortality_survey, -latitude_degrees, -orientation_degrees,-solar_azimuth)

```

# Assembling tide data

```{r}

tides_cp <- read_delim("../raw_data/tides/tides_CP.csv", col_names = c("date","junk","time","tz","tide_height_m")) %>% mutate(hour = hour(time), site_code = "CP") %>% select(-junk, -tz, -time)

tides_tp <- read_delim("../raw_data/tides/tides_TP.csv", col_names = c("date","junk","time","tz","tide_height_m")) %>% mutate(hour = hour(time), site_code = "TP") %>% select(-junk, -tz, -time) 

tides_rest <- read_csv("../raw_data/tides/tides_other_sites.csv") %>% pivot_longer(names_to = "hour", values_to = "tide_height_m", cols = 3:length(.)) %>% mutate(hour = as.integer(hour))

tides_full <- rbind(rbind(tides_cp, tides_tp),tides_rest)

#write_csv(tides_full, "../clean_data/SBHW_tides_clean.csv")

tides_summary <- read_csv("../clean_data/SBHW_tides_clean.csv") %>% group_by(site_code, date) %>% mutate(low_water = min(tide_height_m)) %>% ungroup() %>% filter(tide_height_m == low_water) %>% group_by(site_code) %>% summarize(mean_low_tide_time = mean(hour))

with.tides <- explanatory.variables %>% left_join(tides_summary)

```


# Generating dataframe for modeling

```{r, message = F, results = "hide"}
# now to get response data read in

mortality <- read_csv("../raw_data/mortality/SBC_MORT_surveys.csv") %>% 
  select(-cover_live, -cover_dead, -algal_cover_per25sq)

mort.model.df <- mortality %>% full_join(with.tides) %>% 
  mutate(prop_dead = number_dead/(number_dead+number_live)) %>% filter(is.nan(prop_dead) == F)

```
```{r}
# examining the mortality data

hist(mort.model.df$prop_dead, breaks = 50, xlab = "Proportion dead", main = "Histogram of mortality data")

```

Based on the distribution of these data, a beta model may not be the way to go. The data have an extreme case of zero-inflation, but I don't believe that different processes are causing mortality vs. no mortality, so a hurdle ZOIB model seems inappropriate. Starting off with a Tweedie distribution, while imperfect, may be the best option.

# Model building

Our initial explantory variables will include:

- mean max daily temperature (whole period)
- mean max daily temperature (heat dome only) 
- longitude 
- algal cover 
- number of anemones

Random effects will include:

- site
- transect nested within site

```{r, message=F, results="hide"}
pkgs <- c("tidyverse", "glmmTMB", "DHARMa","lme4","car","ggeffects", "GGally")
invisible(lapply(pkgs, library, character=T))
rm(pkgs)

```

```{r}
# check correlation of temperature variables
#ggpairs(mort.model.df %>% select(mean_daily_max_temp,mean_daily_max_temp_hw,mean_daily_temp,mean_daily_temp_hw))

mort.mod.0 <- glmmTMB(prop_dead ~ mean_daily_max_temp_hw + mean_low_tide_time + algal_prop_cover + degrees_from_azimuth + (1 | site_code), data = mort.model.df, family = binomial(link = "logit"))

plot(density(residuals(mort.mod.0, type = "response"))) # has a long tail ... data are overdispersed ... need to look at other fixes.

mort.mod.1 <- glmmTMB(prop_dead ~ mean_daily_max_temp_hw + mean_low_tide_time + algal_prop_cover + degrees_from_azimuth + (1 | site_code/transect), data = mort.model.df, family = tweedie())

plot(simulateResiduals(mort.mod.1)) # this seems to work. 

#try the beta model since this is more correct

mort.mod.2 <- glmmTMB((prop_dead*nrow(mort.model.df)+0.5)/nrow(mort.model.df) ~ mean_daily_max_temp_hw + mean_low_tide_time + algal_prop_cover + degrees_from_azimuth + (1 | site_code/transect), data = mort.model.df, family = beta_family())

plot(simulateResiduals(mort.mod.2)) # the error distribution family seems wrong. Stick with Tweedie!

```

The residuals look reasonable!
 
```{r}

summary(mort.mod.1)
plot(residuals(mort.mod.1))

```
 
```{r}

Anova(mort.mod.1)

```

```{r, include=F, results="hide"}

mort.summary <- mort.model.df %>% mutate(site_code = factor(site_code)) %>% group_by(site_code, longitude_degrees, degrees_from_azimuth, mean_low_tide_time) %>% summarize(average_mort = mean(prop_dead, na.rm = T), average_maxtemp = mean(mean_daily_max_temp_hw)) %>% mutate(site_code = factor(site_code))

```

# Plots

The follows are some plots that might be of interest.

First, a plot of mortality across sites, coded by temperature (note that sites are arranged from W to E in their longitude across the x-axis).

```{r, echo = F}
require(tidyverse)
library(wesanderson)

new.dat <- data.frame(degrees_from_azimuth = mort.model.df$degrees_from_azimuth, 
                      mean_daily_max_temp_hw = median(mort.model.df$mean_daily_max_temp_hw),
                      algal_prop_cover = median(mort.model.df$algal_prop_cover, na.rm = T),
                      mean_low_tide_time = median(mort.model.df$mean_low_tide_time),
                      site_code = mort.model.df$site_code, transect = mort.model.df$transect)
new.dat$fit <- predict(mort.mod.1, new.dat %>% na.omit(), type = "response")

pal <- wes_palette("Zissou1", 20, type = "continuous")

mort.plot <- ggplot(data = mort.model.df, aes(col = degrees_from_azimuth, y = prop_dead*100, x = mean_daily_max_temp_hw)) + geom_jitter(size = 2, width = 0.2, alpha = 0.8) + scale_color_gradientn(colors = pal, trans="reverse") + theme_classic() + labs(y = "Mortality (%)", col = "Aspect (º)", x = "Mean maximum daily temperature (ºC)") + theme(axis.title = element_text(size = 14), axis.text = element_text(size = 12), legend.text = element_text(size = 12), legend.title = element_text(size = 14)) + geom_smooth(aes(y = fit*100), data= new.dat, method = "lm", se = T, col= "black")
mort.plot

ggsave(filename = "../outputs/Fig3.png", dpi = 1200, mort.plot, height = 2.5, width = 3.5, units = "in", scale = 1.5)

```

No real patterns, which is cool -- across site factors can't explain too much of the variation in mortality.
